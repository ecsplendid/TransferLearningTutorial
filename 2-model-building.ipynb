{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Microsoft Corporation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning using Keras with CNTK backend and LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: Make sure the kernel is set to \"Your project name myvm\" which can be done from the *Kernel* menu under *Change kernel*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will be classifying the images you prepared in the first notebook into two categories using transfer learning. One major transfer learning scenario is to use a network that is pretrained on a large image dataset. Here, you will use a [Convolutional Neural Network (CNN)](https://en.wikipedia.org/wiki/Convolutional_neural_network) architecture called [ResNet50](https://arxiv.org/abs/1512.03385), pretrained on [ImageNet](https://en.wikipedia.org/wiki/ImageNet) dataset  which contains 1.2 million images with 1000 categories. You will first remove the last network layer to generate visual features of the images. You will then use these features to train a boosted decision tree to classify the images as pass or fail. You will use [Keras](https://keras.io/) with [Microsoft Cognitive Toolkit CNTK](https://github.com/Microsoft/cntk) backend for the CNN and [LightGBM](https://lightgbm.readthedocs.io/en/latest/) for binary classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "from glob import iglob\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import lightgbm as lgb\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"cntk\"\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.logging import get_azureml_logger\n",
    "logger = get_azureml_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training features and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the AZUREML_NATIVE_SHARE_DIRECTORY to save your intermediate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.environ['AZUREML_NATIVE_SHARE_DIRECTORY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in the fail and pass images and check the number of images in each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fail images: 12500\n",
      "Number of pass images: 12500\n"
     ]
    }
   ],
   "source": [
    "files_path = path.join(save_path, 'train')\n",
    "fail_files = sorted(iglob(path.join(files_path, '*fail*.jpg')))\n",
    "pass_files = sorted(iglob(path.join(files_path, '*pass*.jpg')))\n",
    "print('Number of fail images: ' + str(len(fail_files)))\n",
    "print('Number of pass images: ' + str(len(pass_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, prepare the labels of the images. You will be labeling fail images with 0 and pass images with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = fail_files + pass_files\n",
    "total_files = len(fail_files) + len(pass_files)\n",
    "labels = np.zeros(total_files)\n",
    "labels[len(fail_files):] = 1\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you will use ResNet50 model with weights pretrained on ImageNet to obtain the features of the images. Download the model and save it into a keras model object. The include_top=False parameter is required to indicate that you will not include the fully-connected layer at the top of the network since you will only use the network to featurize images. The default input image size for this model is (224, 244) with 3 color channnels and requires input_shape=(224, 224, 3) parameter to be set as 'channels_last'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "92905472/94653016 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = ResNet50(include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will use two helper functions, one for yielding batch size image paths from a list of file paths and the other one for  featurizing these batches of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_batch(file_list, batch_size):\n",
    "    for i in range(0, len(file_list), batch_size):\n",
    "        yield file_list[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_images(file_list, model, batch_size=32):\n",
    "    features = []\n",
    "    \n",
    "    for fb in tqdm(file_batch(file_list, batch_size)):\n",
    "        load_img = []\n",
    "        for file_path in fb:\n",
    "            img = image.load_img(file_path, target_size=(224, 224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            load_img.append(preprocess_input(x))\n",
    "        features.extend(model.predict_on_batch(np.concatenate(load_img)).squeeze())\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The featurize_images function  processes the image files in small chunks (default is set to batch_size=32) by first loading the images in the batch into a target size of (224,224), then converting them into four dimensional tensors which keras model expects as input. After, that model's batch prediction method is called to calculate the features of each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will call the function to compute the features and save them into the share folder. The execution of the following cell may take up to 10-15 minutes so feel free to read through the links provided in the beginning of the notebook in order to learn more about CNNs, ResNet50, Keras, CNTK and LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "782it [11:47,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 8s, sys: 58.3 s, total: 11min 7s\n",
      "Wall time: 11min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_filename = path.join(save_path, 'features_resnet50.npy')\n",
    "if path.isfile(features_filename):\n",
    "    print(\"Features found!\")\n",
    "    features = np.load(features_filename)\n",
    "else:\n",
    "    print(\"Computing features\")\n",
    "    features = featurize_images(image_paths, model) \n",
    "    np.save(features_filename, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the computed features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2048)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will use the features calcuated in the previous section to train a LightGBM classifier. You will be performing cross validation to understand the performance of the model. You will use [scikit-learn's stratified K-fold cross validation](http://scikit-learn.org/0.16/modules/generated/sklearn.cross_validation.StratifiedKFold.html) where the folds are made by preserving the percentage of samples from each class. This is an important step especially if you are using your own data and number of images in one of the categories is substentially less than the other category. You will be using 5 fold cross validation. You can pick other values by changing n_splits in the next cell to the desired number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=2048, shuffle=True)\n",
    "cv_results = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'F1', 'AUC', 'Confusion Matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use a helper function called classification_metircs to calculate the evaluation metrics for each fold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(y_true, y_pred_proba, threshold=0.5):\n",
    "    y_pred = np.where(y_pred_proba > threshold, 1, 0)\n",
    "    cm_dict = {}\n",
    "    cm_dict['Accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    cm_dict['Precision'] =  precision_score(y_true, y_pred)\n",
    "    cm_dict['Recall'] =  recall_score(y_true, y_pred)\n",
    "    cm_dict['F1'] =  f1_score(y_true, y_pred) \n",
    "    cm_dict['AUC'] = roc_auc_score(y_true, y_pred_proba)\n",
    "    cm_dict['Confusion Matrix'] = confusion_matrix(y_true, y_pred).tolist()\n",
    "    return cm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, provide parameters of the LightGBM model. You can experiment with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 256,\n",
    "           'learning_rate': 0.1,\n",
    "           'min_split_gain': 0.1,\n",
    "           'min_child_weight': 30,\n",
    "           'reg_lambda': 1,\n",
    "           'subsample': 1,\n",
    "           'objective':'binary',\n",
    "           'task': 'train',\n",
    "           'verbose': 4\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will train your classifer for each fold and print the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:17, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.98685782556750301, 'Recall': 0.99119999999999997, 'F1': 0.9890241468768709, 'AUC': 0.99931535999999999, 'Accuracy': 0.98899999999999999, 'Confusion Matrix': [[2467, 33], [22, 2478]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:35, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.98374306106264864, 'Recall': 0.99239999999999995, 'F1': 0.98805256869772995, 'AUC': 0.99951455999999994, 'Accuracy': 0.98799999999999999, 'Confusion Matrix': [[2459, 41], [19, 2481]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:52, 17.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.98445595854922274, 'Recall': 0.98799999999999999, 'F1': 0.98622479536833696, 'AUC': 0.99931712000000006, 'Accuracy': 0.98619999999999997, 'Confusion Matrix': [[2461, 39], [30, 2470]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:10, 17.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.98447452229299359, 'Recall': 0.98919999999999997, 'F1': 0.98683160415003979, 'AUC': 0.9994075200000001, 'Accuracy': 0.98680000000000001, 'Confusion Matrix': [[2461, 39], [27, 2473]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [01:28, 17.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.98758510212254702, 'Recall': 0.98640000000000005, 'F1': 0.98699219531719029, 'AUC': 0.99890223999999994, 'Accuracy': 0.98699999999999999, 'Confusion Matrix': [[2469, 31], [34, 2466]]}\n",
      "CPU times: user 12min 19s, sys: 9.28 s, total: 12min 29s\n",
      "Wall time: 1min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for train_index, test_index in tqdm(skf.split(features, labels)):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "    clf = lgb.train(params, lgb_train, num_boost_round=500)\n",
    "    y_pred_proba = clf.predict(X_test)\n",
    "    cm_dict = classification_metrics(y_test, y_pred_proba)\n",
    "    print(cm_dict)\n",
    "    cv_results = cv_results.append(classification_metrics(y_test, y_pred_proba),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy     0.987400\n",
       "Precision    0.985423\n",
       "Recall       0.989440\n",
       "F1           0.987425\n",
       "AUC          0.999291\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you will be using Azure Machine Learning Workbench's data collector to log the metrics of your cross validation. The metrics are stored by the history service and tied to the notebook that produced them. You can later view these metrics in the Run History tab of Azure ML Workbench. We will turn the cell level logging on before logging and turn it off after so that only the history of cell runs where metrics are collected are captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History logging enabled\n",
      "History logging is enabled\n"
     ]
    }
   ],
   "source": [
    "%azureml history on\n",
    "%azureml history show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azureml.logging.script_run_request.ScriptRunRequest at 0x7f48021fae48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.log('Accuracy',cv_results.mean()['Accuracy'])\n",
    "logger.log('Precision',cv_results.mean()['Precision'])\n",
    "logger.log('Recall',cv_results.mean()['Recall'])\n",
    "logger.log('F1',cv_results.mean()['F1'])\n",
    "logger.log('AUC',cv_results.mean()['AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History logging disabled\n"
     ]
    }
   ],
   "source": [
    "%azureml history off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will train our model on the whole dataset one last time to obtain the final trained model for operationalization. You will also plot the confusion matrix for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(features, labels, free_raw_data=False)\n",
    "clf = lgb.train(params, lgb_train, num_boost_round=500)\n",
    "y_pred_proba = clf.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the following helper function to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"Plots a confusion matrix.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    cm_max = cm.max()\n",
    "    cm_min = cm.min()\n",
    "    if cm_min > 0: cm_min = 0\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm_max = 1\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    thresh = cm_max / 2.\n",
    "    plt.clim(cm_min, cm_max)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i,\n",
    "                 round(cm[i, j], 3),  # round to 3 decimals if they are float\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEkCAYAAABT65ihAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm8VWW9x/HPFxBFQSBxiAOEA0ri\nLGKZhpY5BIo3LVG0uHq1waHyWjnlmDnd8mpahmkamqCWiYpi1zLTHEAcwQkHElARVJxR8Hf/WOvo\nPptz9l7nsId1zvm+e62Xe6317Gf9tuSPZ61nWIoIzMzsE13qHYCZWd44MZqZFXFiNDMr4sRoZlbE\nidHMrIgTo5lZESdGa0JSD0k3SVoi6bqVqGecpNsrGVu9SNpJ0lP1jsNqRx7H2D5JOhA4BhgKvAU8\nDJwZEXevZL0HA0cBO0TEspUONOckBTAkIubUOxbLD7cY2yFJxwD/C/wcWBcYBPwaGFOB6j8DPN0Z\nkmIWkrrVOwarg4jw1o42oDfwNvD1EmVWJUmcC9Ltf4FV03M7A/OA/wYWAi8B/5meOw34APgwvcah\nwKnAVQV1DwYC6JbujweeI2m1Pg+MKzh+d8H3dgCmA0vSf+5QcO5O4AzgnrSe24F+Lfy2xvh/XBD/\nPsBXgaeB14ATCsqPAO4F3kjLXgR0T8/dlf6Wd9Lfu39B/T8BXgYmNh5Lv7Nheo1t0v3+wKvAzvX+\n/4a3ym1uMbY/nwdWA24oUeZE4HPAVsCWJMnhpILz65Ek2AaS5HexpL4RcQpJK3RyRPSMiMtKBSJp\nDeBCYM+I6EWS/B5uptyngFvSsmsBvwRukbRWQbEDgf8E1gG6A8eWuPR6JP8OGoCTgUuBg4BtgZ2A\nn0paPy27HPgh0I/k392Xge8BRMQX0zJbpr93ckH9nyJpPR9eeOGIeJYkaV4laXXg98CVEXFniXit\nnXFibH/WAhZF6VvdccDpEbEwIl4laQkeXHD+w/T8hxExlaS1tEkb4/kI2ExSj4h4KSJmNVNmFPBM\nREyMiGURcQ3wJLBXQZnfR8TTEfEecC1JUm/JhyTPUz8EJpEkvQsi4q30+rNJ/kIgIh6MiPvS674A\n/BYYmeE3nRIRS9N4moiIS4E5wP3Ap0n+IrIOxImx/VkM9Cvz7Ks/MLdgf2567OM6ihLru0DP1gYS\nEe+Q3H5+B3hJ0i2ShmaIpzGmhoL9l1sRz+KIWJ5+bkxcrxScf6/x+5I2lnSzpJclvUnSIu5Xom6A\nVyPi/TJlLgU2A34VEUvLlLV2xomx/bkXWEryXK0lC0huAxsNSo+1xTvA6gX76xWejIhpEfEVkpbT\nkyQJo1w8jTHNb2NMrfEbkriGRMSawAmAynyn5FANST1JntteBpyaPiqwDsSJsZ2JiCUkz9UulrSP\npNUlrSJpT0nnpsWuAU6StLakfmn5q9p4yYeBL0oaJKk3cHzjCUnrShqTPmtcSnJL/lEzdUwFNpZ0\noKRukvYHNgVubmNMrdELeBN4O23Nfrfo/CvABq2s8wJgRkT8F8mz00tWOkrLFSfGdigifkEyhvEk\nkh7RF4Ejgb+kRX4GzAAeBR4DZqbH2nKtvwKT07oepGky65LGsYCkp3YkKyYeImIxMJqkJ3wxSY/y\n6IhY1JaYWulYko6dt0has5OLzp8KXCnpDUnfKFeZpDHAHnzyO48BtpE0rmIRW915gLeZWRG3GM3M\nijgxmlm7JelySQslPd7CeUm6UNIcSY9K2iZLvU6MZtaeXUHyzLclewJD0u1wklEKZTkxmlm7FRF3\nkXT8tWQM8IdI3Af0kfTpcvU6MZpZR9ZAMmqj0TyaTixoVodaOUTdeoS696p3GNYKW392UL1DsFaa\nOfPBRRGxdlu/33XNz0QsW2GmZbPivVdnAYWzkCZExIS2XjurjpUYu/di1U3KDkWzHLnn/ovqHYK1\nUo9VVDy9s1Vi2fusOnRsprLvP/Sr9yNi+Epcbj4wsGB/ABlmXPlW2sxqS4CUbVt5U4Bvpr3TnwOW\nRMRL5b7UoVqMZtZOqDJtMknXkKyX2U/SPOAUYBWAiLiEZDrqV0lWQ3qXZGm7spwYzaz2KtMaJCIO\nKHM+gCNaW68To5nVmCrWYqwWJ0Yzq70KtRirxYnRzGpLgi5d6x1FSU6MZlZ7vpU2MyviW2kzs0Lu\nfDEza6pxgHeOOTGaWe25xWhmVkjQ1b3SZmafEG4xmpmtwM8YzcwKuVfazGxFbjGamRXwlEAzs2b4\nVtrMrIhvpc3MCrnzxcxsRW4xmpkV8ABvM7Ni7pU2M1uRW4xmZkX8jNHMrIDcK21mtiK3GM3MPiGg\nSxe3GM3MPqF0yzEnRjOrMSHfSpuZNeXEaGZWxInRzKyIE6OZWQFJqIsTo5lZE24xmpkVcWI0Myvi\nxGhmVqgdDPDO97wcM+uQJGXaMta1h6SnJM2RdFwz5wdJ+rukhyQ9Kumr5ep0i9HMakqoYnOlJXUF\nLga+AswDpkuaEhGzC4qdBFwbEb+RtCkwFRhcql63GM2s9pRxK28EMCcinouID4BJwJiiMgGsmX7u\nDSwoV6lbjGZWW6po50sD8GLB/jxg+6IypwK3SzoKWAPYtVylbjGaWc214hljP0kzCrbD23C5A4Ar\nImIA8FVgolR6pVy3GM2s5lrRYlwUEcNLnJ8PDCzYH5AeK3QosAdARNwraTWgH7CwpUrdYjSzmhLJ\nlMAsWwbTgSGS1pfUHRgLTCkq82/gywCSPgusBrxaqlInxhy55JRxzL3jLGZcd0KLZX7x4/14/MZT\neGDy8Ww1dEANo7Pm3D7tNrYYtgnDhm7EeeeevcL5pUuXctCB+zNs6EbstMP2zH3hhdoHmTeq3HCd\niFgGHAlMA54g6X2eJel0SXunxf4bOEzSI8A1wPiIiFL1OjHmyMSb7mPMERe3eH73HTdlw0Frs9mY\n0zjyZ9dw4QljaxidFVu+fDk/OPoIbrzpVh56dDbXTbqGJ2bPblLmissvo2+fvsx6cg5Hff+HnHjC\nT+oUbb5UchxjREyNiI0jYsOIODM9dnJETEk/z46IL0TElhGxVUTcXq5OJ8YcuWfms7y25N0Wz48e\nuQV/vPkBAB547AV69+rBev3WbLG8Vdf0Bx5gww03Yv0NNqB79+58ff+x3HzTjU3K3HzTjYw7+FsA\nfG3f/bjzb3dQprHSKVQyMVaDE2M70n+dPsx7+fWP9+e/8gb91+lTx4g6twUL5jNgwCfP/RsaBjB/\n/vwVywxMynTr1o01e/dm8eLFNY0zlyo3jrEq6pYYJR0t6QlJV7dwfrikC9PP4yVdVNsIzaxa8t5i\nrOdwne8Bu0bEvOZORsQMYEZtQ8q3BQvfYMB6fT/eb1i3DwsWvlHHiDq3/v0bmDfvk7HF8+fPo6Gh\nYcUyL77IgAEDWLZsGW8uWcJaa61V61BzRarclMBqqUt0ki4BNgBulfQTSfemE7z/JWmTtMzOkm6u\nR3x5dcs/HuPA0SMAGLH5YN58+z1eXvRmnaPqvIZvtx1z5jzDC88/zwcffMB1kycxavTeTcqMGr03\nV0+8EoA//+l6Ru7ypdwvuVULbjE2IyK+I2kPYBfgA+AXEbFM0q7Az4F9s9aVjoRPRsOv0rMK0dbO\nlWeNZ6dth9CvT0/m3HYGZ1wylVW6dQXgd9ffzW13z2L3HYcxa8opvPv+h3z71KvqHHHn1q1bN86/\n4CL2GrU7y5cv51vjD2HTYcM4/dST2Wbb4Yzea2/GH3Ioh4w/mGFDN6Jv308x8epJ9Q47H3L+d4Pq\n1UMm6QVgONADuBAYQjLZe5WIGCppZ+DYiBgtaTwwPCKOLFVnl9XXiVU3+UZV47bKen26Hx23Nz1W\n0YNlZqOUtOq6Q6Jh3AWZyj5//qiVulZb5eFG/wzg7xGxGbAXyah0M+uoKjjAu1ryMFe6N5/MbRxf\nxzjMrAYE5P0xax5ajOcCZ0l6iHwkajOrKtGlS7atXuqWiCJicPpxEbBxwamT0vN3Anemn68ArqhV\nbGZWXXnvmXcLzcxqS/m/lXZiNLOaEtT1NjkLJ0Yzqzm3GM3MCsktRjOzJpLhOk6MZmYF6jt4Owsn\nRjOruZznRSdGM6s9txjNzAp5HKOZWVMex2hm1gzfSpuZFcl5XnRiNLMak1uMZmZNtIf1GJ0YzazG\nPMDbzGwF7pU2MyvkcYxmZk15EQkzs2Y4MZqZFcl5XnRiNLMa80K1ZmZNycN1zMxWlPO8SJd6B2Bm\nnU8XKdOWhaQ9JD0laY6k41oo8w1JsyXNkvTHcnW6xWhmNVepFqOkrsDFwFeAecB0SVMiYnZBmSHA\n8cAXIuJ1SeuUq7fFxChpzVJfjIg3swZvZtZIlV1EYgQwJyKeS+rWJGAMMLugzGHAxRHxOkBELCxX\naakW4ywgSMZjNmrcD2BQa6I3M2vUtXK90g3AiwX784Dti8psDCDpHqArcGpE3Faq0hYTY0QMbFuc\nZmaltaLB2E/SjIL9CRExoZWX6wYMAXYGBgB3Sdo8It4o9YWyJI0FNoiIn0saAKwbEQ+2Mjgzs2RK\nIJkz46KIGF7i/HygsBE3ID1WaB5wf0R8CDwv6WmSRDm9pUrL9kpLugjYBTg4PfQucEm575mZtaSL\nsm0ZTAeGSFpfUndgLDClqMxfSFqLSOpHcmv9XKlKs7QYd4iIbSQ9BBARr6UBmJm1nio3wDsilkk6\nEphG8vzw8oiYJel0YEZETEnP7SZpNrAc+FFELC5Vb5bE+KGkLiQdLkhaC/hoJX6LmXVioqKdL0TE\nVGBq0bGTCz4HcEy6ZZJlgPfFwJ+AtSWdBtwNnJP1AmZmxaRsW72UbTFGxB8kPQjsmh76ekQ8Xt2w\nzKwj6yhzpbsCH5LcTnsaoZm1Wb1bg1lk6ZU+EbgG6E/SFf5HScdXOzAz67gqOVe6GrK0GL8JbB0R\n7wJIOhN4CDirmoGZWceV8wZjpsT4UlG5bukxM7NWq3SvdDWUWkTifJJniq8BsyRNS/d3o8SIcTOz\nkio4jrFaSrUYG3ueZwG3FBy/r3rhmFlnkPO8WHIRictqGYiZdR7tucUIgKQNgTOBTYHVGo9HxMZV\njMvMOiiReR503WQZk3gF8HuS37MncC0wuYoxmVkHp/Q5Y7mtXrIkxtUjYhpARDwbESeRJEgzs1aT\noKuUaauXLMN1lqaLSDwr6Tska531qm5YZtaR5fwRY6bE+ENgDeBokmeNvYFDqhmUmXVs7b7zJSLu\nTz++xSeL1ZqZtVnO82LJAd43kK7B2JyI+FpVIjKzDk3Udx50FqVajBfVLAoz6zwEXXI+XqfUAO87\nahlIJWz92UHcc7/zeXvSd7sj6x2C1UHe1y7Muh6jmVlFiA7Q+WJmVmk5v5POnhglrRoRS6sZjJl1\nDnlPjFlW8B4h6THgmXR/S0m/qnpkZtYhJa82aP9TAi8ERgOLASLiEWCXagZlZh1b1y7ZtnrJcivd\nJSLmFmXv5VWKx8w6uGR1nXzfS2dJjC9KGgGEpK7AUcDT1Q3LzDqyjjBc57skt9ODgFeA/0uPmZm1\nSc4bjJnmSi8ExtYgFjPrBFTnV6NmkWUF70tpZs50RBxelYjMrMPLeV7MdCv9fwWfVwP+A3ixOuGY\nWUcnoFvOBzJmuZVu8hoDSROBu6sWkZl1eB2hxVhsfWDdSgdiZp2E8j/zJcszxtf55BljF+A14Lhq\nBmVmHZvId2YsmRiVjOrekuQ9LwAfRUSLi9eamZXTHl6fWjIxRkRImhoRm9UqIDPr+LrmPDNmGYD+\nsKStqx6JmXUKjS3GLFu9tJgYJTW2JrcGpkt6StJMSQ9Jmlmb8Mysw1HjCjvlt0zVSXuk+WmOpBb7\nPyTtKykkDS9XZ6lb6QeAbYC9s4VnZpZNpWa+pOs3XAx8BZhH0oibEhGzi8r1Ar4P3L9iLSsqlRgF\nEBHPtiliM7NmVLjzZQQwJyKeA5A0CRgDzC4qdwZwDvCjLJWWSoxrSzqmpZMR8cssFzAzK1bBAd4N\nNJ2JNw/Yvum1tA0wMCJukbTSibEr0BNyPuDIzNoVIbpmz4z9JM0o2J8QERMyX0vqAvwSGJ89wtKJ\n8aWIOL01lZmZldW6HudFEVGqs2Q+MLBgfwCfjLsG6AVsBtyZLra9HjBF0t4RUZhwmyj7jNHMrNIq\nuOzYdGCIpPVJEuJY4MDGkxGxBOjXuC/pTuDYUkkRSo9j/PLKRGtm1pzkvdKVGa4TEcuAI4FpwBPA\ntRExS9Lpkto8oqbFFmNEvNbWSs3MSqnkQrURMRWYWnTs5BbK7pylzrasrmNmtlI64rJjZmZtJtGa\nXum6cGI0s5rLd1p0YjSzGuso75U2M6uofKdFJ0Yzq4OcNxidGM2stlo5JbAunBjNrObkxGhm1lS+\n06ITo5nVmtxiNDNrQmR72VQ9OTGaWc25xWhmViTnb091YjSz2kpupfOdGZ0Yzazmcn4n7cRoZrUm\n5BajmVlTbjGamRXweoxmZs3IeV7M/TjLTuX2abexxbBNGDZ0I8479+wVzi9dupSDDtyfYUM3Yqcd\ntmfuCy/UPkj72CWnjGPuHWcx47oTWizzix/vx+M3nsIDk49nq6EDahhdvinj/+rFiTEnli9fzg+O\nPoIbb7qVhx6dzXWTruGJ2bOblLni8svo26cvs56cw1Hf/yEnnvCTOkVrABNvuo8xR1zc4vndd9yU\nDQetzWZjTuPIn13DhSeMrWF0+ZUsVJttqxcnxpyY/sADbLjhRqy/wQZ0796dr+8/lptvurFJmZtv\nupFxB38LgK/tux93/u0OIqIe4Rpwz8xneW3Juy2eHz1yC/548wMAPPDYC/Tu1YP1+q1Zq/ByzS1G\ny2TBgvkMGDDw4/2GhgHMnz9/xTIDkzLdunVjzd69Wbx4cU3jtOz6r9OHeS+//vH+/FfeoP86feoY\nUX5U6r3S1eLOFzOrKZH/Xmm3GHOif/8G5s178eP9+fPn0dDQsGKZF5Myy5Yt480lS1hrrbVqGqdl\nt2DhGwxYr+/H+w3r9mHBwjfqGFFeZL2R7oC30pIGS3pS0tWSnpB0vaTVJZ0sabqkxyVNULrMhqSj\nJc2W9KikSemxkZIeTreHJPWqVrz1Nny77Zgz5xleeP55PvjgA66bPIlRo/duUmbU6L25euKVAPz5\nT9czcpcv5X6Vks7sln88xoGjRwAwYvPBvPn2e7y86M06R5UDGW+jO/Kt9CbAoRFxj6TLge8BF0XE\n6QCSJgKjgZuA44D1I2KppMYHMccCR6Tf7wm8X+V466Zbt26cf8FF7DVqd5YvX863xh/CpsOGcfqp\nJ7PNtsMZvdfejD/kUA4ZfzDDhm5E376fYuLVk+oddqd25Vnj2WnbIfTr05M5t53BGZdMZZVuXQH4\n3fV3c9vds9h9x2HMmnIK777/Id8+9ao6R5wfef/rXNXq1ZQ0GLgrIgal+18CjgYmAj8GVgc+Bfwq\nIs6WdBvwNvAX4C8R8bak44D/AK4G/hwR85q5zuHA4QADBw3a9uln51bl91h19N3uyHqHYK30/sMX\nPxgRw9v6/c9uvnVcfsPfM5XdYUjflbpWW1X7GWNx1g3g18B+EbE5cCmwWnpuFHAxsA0wXVK3iDgb\n+C+gB3CPpKErXCBiQkQMj4jha/dbu1q/w8wqSBm3eql2Yhwk6fPp5wOBu9PPi9Jb4/0AJHUBBkbE\n34GfAL2BnpI2jIjHIuIcYDqwQmI0s/ZHUqatXqr9jPEp4Ij0+eJs4DdAX+Bx4GWSZAfQFbhKUm+S\nvygujIg3JJ0haRfgI2AWcGuV4zWzGsh7n2G1E+OyiDio6NhJ6VZsx+IDEXFUVaIys7rKeV70AG8z\nq4OcZ8aqJcaIeAHYrFr1m1n7lHSs5DszeuaLmdVWxpV1sq6uI2kPSU9JmpMO8Ss+f0zB5JE7JH2m\nXJ1OjGZWexUaryOpK8kwvz2BTYEDJG1aVOwhYHhEbAFcD5xbrl4nRjOrsYrOlR4BzImI5yLiA2AS\nMKawQET8PSIa14e7Dyi7YrATo5nVXAXnSjcALxbsz0uPteRQMgz7c6+0mdVUK2e19JM0o2B/QkRM\naNN1pYOA4cDIcmWdGM2s9rJnxkVl5krPBwYW7A9IjzW9nLQrcCIwMiKWlruoE6OZ1VyXyk19mQ4M\nkbQ+SUIcSzL9+GOStgZ+C+wREQszxVep6MzMsqrUIhIRsQw4EpgGPAFcGxGzJJ0uqXFB0/OAnsB1\n6dquU8rV6xajmdVWhZfOiYipwNSiYycXfN61tXU6MZpZzeV95osTo5nVlPDqOmZmK8h5XnRiNLPa\ny/tL3JwYzazmcp4XnRjNrPZynhedGM2sDnKeGZ0Yzaym2sNCtU6MZlZbrViEtl6cGM2s9pwYzcwK\nZV6Etm6cGM2s5jxcx8ysQIXXkKgKJ0Yzq72cZ0YnRjOruQouVFsVToxmVnP5TotOjGZWa9nfAFg3\nToxmVgf5zoxOjGZWU16o1sysGTnPi06MZlZ77pU2MyuW77zoxGhmtZfzvOjEaGa1JQ/XMTNbkVfX\nMTMr4hajmVkRJ0Yzsya8UK2ZWRPtYeZLl3oHYGaWN24xmlnN5b3F6MRoZrUlTwk0M2vC73wxM2tO\nzjOjE6OZ1Vzeh+u4V9rMaq5xvnS5LVtd2kPSU5LmSDqumfOrSpqcnr9f0uBydToxmlnNKeNWth6p\nK3AxsCewKXCApE2Lih0KvB4RGwHnA+eUq9eJ0cxqTlKmLYMRwJyIeC4iPgAmAWOKyowBrkw/Xw98\nWWUqd2I0s5pqnPlSoVvpBuDFgv156bFmy0TEMmAJsFapSjtU58vMmQ8u6rGK5tY7jiroByyqdxDW\nKh35z+wzK/PlmTMfnNZjFfXLWHw1STMK9idExISVuX4WHSoxRsTa9Y6hGiTNiIjh9Y7DsvOfWcsi\nYo8KVjcfGFiwPyA91lyZeZK6Ab2BxaUq9a20mbVn04EhktaX1B0YC0wpKjMF+Fb6eT/gbxERpSrt\nUC1GM+tcImKZpCOBaUBX4PKImCXpdGBGREwBLgMmSpoDvEaSPEtSmcRpOSDp8Fo8V7HK8Z9Z++bE\naGZWxM8YzcyKODG2A5J61TsGs87EiTHnJG0A/I+k7eodi1ln4cSYY+nwg/eBl4BvStqmziFZG0mZ\nBzRbDjgx5pSkjYHTImIB8AfgFeAwJ8f2R9Io4DZJny43R9fywb3SOSVpXWAZMBhYkH7+Nsm8z0sj\nYmb9orOsJO1MsvrLYRHxL0lrRMQ7dQ7LynCLMaci4hXgXWAcyX9YAn5LMr3pEEkj6hieZTeAZKmr\n9yQdCtwl6aeSPl3nuKwEJ8acUKLJn0dEvAecCTwBXMgnyfFNYH9Jq9Y8UMtE0naSGoBXga8BFwCr\nkKwFuDmwTh3DszJ8K50TknpGxNvp528DawJdIuIcSb2B40gmwh9LcltNRHTU1VvaNUl7A6cC34+I\nf0paH3g7Il5NP18PHBoRD9czTmuZW4w5kP6HdEH6+YfAgcD9wDhJV0fEEuDnJPM8zyRZjdhJMYfS\n4VWnA/ulSXEgsGqaFPcBbgDOcFLMN7cY60zSWsBk4EgggJOBw4Cjge3TYx9FxH7pQO8eEbGwXvFa\n8yQpIkLStiR/yZ0O7ApsBuwMjAQ+IkmS/2osX7eArSQnxjpLk911wOskSfB4YH3grIj4fNrJcitw\na0QcVL9IrRRJ/Rpb8ZLOBLYCroyIayUdS/KX2y/rGqRl5mXH6iwi3pL0N5KW4v9ExNz0OdS9aZGh\nwHkk77KwHJI0GjhK0mPA3RFxYsG5HYBDgO/VKz5rPSfGfJgMPAhcJGkxSQtxa0mXk7z9bGREvFDH\n+KwF6TjFM4F9SXqct0+fM15O0vP8e+DYiLizXjFa6zkx5kBEzAXmShpHkiRfJumAaSB5UP98PeOz\nkoaSLHy6Ccm7UC4D9krPXQTslt4F+JliO+LEmCMRMVPSfsDfgOO90Gl+SdoR6A88RzKudBSwb5oE\nxwBbAP0bW/pOiu2LE2PORMQjkkYC79U7Fmte+tzwUpL3jSwnebnSNsBMSfcCPYHz/fij/XKvtFkr\npKMEziFp0d+XPk8cRTIcZwPgA+DciPhzHcO0leQWo1nr9Aa+CHwJuI/kRe7/Bp4GxgOrR8RCP1Ns\n3zzzxawVIuKvJHOfD5F0QER8CLwB7A6s1jj43kmxfXOL0ayVIuJGSR8BV0val2RGy2meptlxuMVo\n1gYRcRNwELARMD0ipqQrJHkh2g7ALUazNkqT4fvA5ZKedYdLx+FeabOVJOkrwLMR8Vy9Y7HKcGI0\nMyviZ4xmZkWcGM3MijgxmpkVcWLsRCQtl/SwpMclXSdp9ZWoa2dJN6ef95Z0XImyfSS1ej1CSaem\ni7xmOl5U5op0QY6s1xos6fHWxmgdkxNj5/JeRGwVEZuRzOn9TuHJ5t5UmEVETImIs0sU6YMXarV2\nxImx8/onsFHaUnpK0h+Ax4GBknaTdK+kmWnLsieApD0kPSlpJsm0ONLj4yVdlH5eV9INkh5Jtx2A\ns4EN09bqeWm5H0maLulRSacV1HWipKcl3U2yxmFJkg5L63lE0p+KWsG7SpqR1jc6Ld9V0nkF1/72\nyv6LtI7HibETktSNZGXwx9JDQ4BfR8Qw4B3gJGDXiNgGmAEcI2k1kqW29gK2BdZrofoLgX9ExJYk\nS3HNInn167Npa/VHknZLrzmC5N0o20r6YvoiqbHpsa8C22X4OX+OiO3S6z0BHFpwbnB6jVHAJelv\nOBRYEhHbpfUflr5KwuxjnvnSufSQ1Pjazn+SrDbdH5gbEfelxz8HbArck85u607y/pmhwPMR8QyA\npKuAw5u5xpeAbwJExHJgiaS+RWV2S7eH0v2eJImyF3BDRLybXmNKht+0maSfkdyu9wSmFZy7NiI+\nAp6R9Fz6G3YDtih4/tg7vfbTGa5lnYQTY+fyXkRsVXggTX7vFB4C/hoRBxSVa/K9lSSStyD+tuga\nP2hDXVcA+6QL/I4neVVpo+LZC5Fe+6iIKEygSBrchmtbB+VbaSt2H/AFSRsBSFpD0sbAk8BgSRum\n5Q5o4ft3AN9Nv9tVUm/gLZLWYKNpJMt2NT67bJC0DnAXsI+kHkpeK7sX5fUCXpK0CjCu6NzXJXVJ\nY94AeCq99nfT8kjaWNIaGa4pTht8AAAAq0lEQVRjnYhbjNZERLyatryukbRqevikiHha0uHALZLe\nJbkV79VMFd8HJkg6lGTZ/+9GxL2S7kmHw9yaPmf8LHBv2mJ9GzgofefNZOARYCHJqwPK+SlwP/Bq\n+s/CmP4NPACsCXwnIt6X9DuSZ48z05VwXgX2yfZvxzoLz5U2MyviW2kzsyJOjGZmRZwYzcyKODGa\nmRVxYjQzK+LEaGZWxInRzKyIE6OZWZH/Bwrx4hmSvmfUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48045093c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[12497     3]\n",
      " [    0 12500]]\n"
     ]
    }
   ],
   "source": [
    "cm = np.asarray(classification_metrics(labels, y_pred_proba)['Confusion Matrix'])\n",
    "plot_confusion_matrix(cm, ['fail','pass'], normalize=True)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model file to the shared folder. You will load this file in the next notebook for operationalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path.join(save_path,'lightgbm_classifier.model')\n",
    "clf.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one option to retrive your model for operationalization, you can  write the file to the special outputs folder which can be accessed from Azure ML workbench under the run history tab for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path.join('outputs','lightgbm_classifier.model')\n",
    "clf.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History logging enabled\n"
     ]
    }
   ],
   "source": [
    "%azureml history on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = path.join('outputs','lightgbm_classifier.model')\n",
    "with open(filepath, \"rb\") as file:\n",
    "    get_azureml_logger().upload(path.normpath(filepath), file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as an option, you can locate the model file in Azure ML Workbench by clicking the last completed run under the notebook run history and download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History logging disabled\n"
     ]
    }
   ],
   "source": [
    "%azureml history off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another option, you will create a folder under AZUREML_NATIVE_SHARE_DIRECTORY where you will save the files needed for operationalization. In the next notebook, you will compress and upload this folder to blob storage for later retrieval and usage for web service deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "o16n_path = path.join(save_path,'o16n')  \n",
    "if not os.path.exists(o16n_path):\n",
    "    os.makedirs(o16n_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path.join(o16n_path,'lightgbm_classifier.model')\n",
    "clf.save_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go to the 3rd notebook to prepare other files needed for operationalization of your model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgtutvso local",
   "language": "python",
   "name": "imgtutvso_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
